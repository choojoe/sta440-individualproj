---
title: "Individual Project: Analyzing Yelp Reviews"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
library("dplyr")
library("stringr")
library("anytime")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library("randomForest")
library("randomForestExplainer")
library("caret")
library("knitr")
library("broom")
library("nnet")
library("kableExtra")
```

```{r load data, include=FALSE}
raw <- read.csv("raw_yelp_review_data.csv")
```

```{r mutate, include=FALSE}
raw <- raw %>%
  mutate(rating = as.factor(substr(raw$star_rating, 1, 2)),
         rating.level = as.factor(case_when(as.numeric(rating) == 5 ~ "Positive",
                                  as.numeric(rating) == 4 ~ "Neutral",
                                  as.numeric(rating) <= 3 ~ "Negative")),
         length = nchar(as.character(raw$full_review_text)),
         exclamations = str_count(raw$full_review_text, "!"),
         questions = str_count(raw$full_review_text, "\\?")
         )
data <- raw
```

```{r text, include=FALSE}
data$full_review_text <- as.character(data$full_review_text)
text <- data$full_review_text
text <- tolower(text)
text <- removeNumbers(text)
text <- removePunctuation(text)
text <- removeWords(text, stopwords("english"))
text <- stripWhitespace(text)
text <- stemDocument(text)
data$full_review_text <- text

corpus <- Corpus(VectorSource(data$full_review_text)) # turn into corpus

tdm <- TermDocumentMatrix(corpus) # create tdm from the corpus

top_terms <- findFreqTerms(tdm,1000)

# sort(top_terms)

data <- data %>%
  mutate(always = case_when(grepl("alway", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         austin = case_when(grepl("austin", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         back = case_when(grepl("back", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         barista = case_when(grepl("barista", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         checkin = case_when(grepl("checkin", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         coffee = case_when(grepl("coff", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         come = case_when(grepl("come", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         day = case_when(grepl("day", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         definite = case_when(grepl("definit", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         drink = case_when(grepl("drink", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         flavor = case_when(grepl("flavor", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         food = case_when(grepl("food", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         friend = case_when(grepl("friend", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         get = case_when(grepl("get", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         good = case_when(grepl("good", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         got = case_when(grepl("got", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         great = case_when(grepl("great", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         ice = case_when(grepl("ice", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         latte = case_when(grepl("latt", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         like = case_when(grepl("like", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         little = case_when(grepl("littl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         look = case_when(grepl("look", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         lot = case_when(grepl("lot", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         love = case_when(grepl("love", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         nice = case_when(grepl("nice", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         order = case_when(grepl("order", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         park = case_when(grepl("park", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         people = case_when(grepl("peopl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         place = case_when(grepl("place", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         pretty = case_when(grepl("pretti", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         really = case_when(grepl("realli", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         seat = case_when(grepl("seat", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         service = case_when(grepl("servic", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         shop = case_when(grepl("shop", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         spot = case_when(grepl("spot", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         staff = case_when(grepl("staff", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         sweet = case_when(grepl("sweet", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         table = case_when(grepl("tabl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         taste = case_when(grepl("tast", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         tea = case_when(grepl("tea", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         time = case_when(grepl("time", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         try = case_when(grepl("tri", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         want = case_when(grepl("want", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         well = case_when(grepl("well", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         will = case_when(grepl("will", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         work = case_when(grepl("work", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0)
  )
```


# Intro

***Background***

Yelp is a website founded in 2004 where users can submit reviews of businesses. The reviews are from a 1-5 star scale system with 1 indicating the worst experience and 5 indicating the best experience. In these reviews, "Yelpers", can also write about their experiences and share photos from their trips to restaurants, coffeeshops, barbers, etc. These reviews are valuable in a variety of ways: they can inform other people of the quality of the experience at said business, they can be a diary for the reviewer to reflect on their experiences, and they can help local businesses receive valuable feedback. In fact, one study claimed that a one-star increase in Yelp rating led to a 5-9% increase in revenue in the Seattle area from 2004-2009 (Luca, 2011). With Yelp reviews being valuable to both customers and businesses, it is important to understand what aspects of a review are associated with negative, neutral, and positive ratings. Are certain words or ways to describe Yelper's experiences good predictors of their rating? Specifically, the interests of this study is to **analyze components of Yelp written reviews to understand the differences in how negative, neutral, and positive ratings are given.**


***Data***

The data for this study is comprised of 7616 individual Yelp reviews that span 79 coffee shops in the Austin, TX area. All previous reviews (with some going back to 2006) were scraped for coffee shops that were operational in 2016. The name of the coffee shop, text of the review, and star ratings were recorded. The star ratings were given a level attribute with 3 stars or less being "Negative", 4 stars being "Neutral", and 5 stars being "Positive." Even though 3 stars is the numerical average of the 5-star system, Yelp has reported that average rating is actually closer to 4, 3.77 to be exact (Bialik, 2018).

A text analysis was conducted with this dataset.
Firstly, the original length, the number of exclamations, and the number of question marks in the reviews were recorded as their own variables. These were the characteristics of Yelp reviews that were particularly interesting as they might be indicators of Yelper's emotions besides their words. For example, perhaps reviewers will be more lively and positive in reviews with many exclamation points, thus their ratings are more likely to be 5s. Critical reviews might be characterized by long rambling rants that point out all the flaws of the coffee shop, and therefore longer reviews will be associated with bad ratings. 
Then through a cleaning process, as well as a method known as "stemming," non-common words with at least 10000 occurrences throughout the reviews were made into binary variables. The full list of words as well as a more detailed walkthrough can be found in Appendix 1.  


***Hypothesis***

Based on anecdotal usage of Yelp as well as some exploratory analysis, we hypothesize that positive reviews (5 stars) will be associated with many action words as well as high usage of exclamation points, neutral reviews (4 stars) will be associated with many nouns or descriptive words, and negative reviews (3 stars or lower) will be associated with more characters and words related to service.

**Figure 1. Distribution of Exclamation Points by Rating**

```{r, echo=FALSE, warning=FALSE}
ggplot(data, aes(x=rating.level, y=exclamations)) +
  geom_boxplot() + 
  labs(x = 'Rating',
       y = 'Number of Exclamation Points') 
```

Figure 1 displays the distribution of exclamation points in a given review separated by the 3 levels of ratings. We see that positive reviews have a higher median number of exclamation points as well as a greater frequency of high exclamation point reviews, with a maximum of 40 exclamation points in 1 review. This aligns with our hypothesis that positive reviews are generally more exciteable and therefore have more exclamation points.

**Figure 2. Length of Review by Rating**

```{r, echo=FALSE, warning=FALSE}
ggplot(data, aes(x=rating.level, y=length)) +
  geom_boxplot() + 
  labs(x = 'Rating',
       y = 'Length of Review (characters)') 
```

Figure 2 depicts the distribution of length of characters for a given review separated by the 3 levels of ratings. We see that the neutral reviews and then positive reviews have fewer number of characters than negative reviews. This sentiment that negative reviews are comprised of longer complaints seem to hold in this coffee shop dataset, which is actually in line with the findings of Yelp in 2018 (Bialik, 2018).

**Table 1: Frequency of Key Words**

```{r, echo=FALSE, warning=FALSE}
table1 <- data %>%
  group_by(rating.level) %>%
  summarise(n = n(),
            barista = sum(as.numeric(barista)),
            like = sum(like),
            love = sum(love),
            nice = sum(nice),
            pretty = sum(pretty),
            service = sum(service)
            ) 
colnames(table1) <- c("Rating Level", "Reviews", "Barista", "Like","Love","Nice","Pretty","Service")
kable(table1)
```

As a precursor to our model and analysis, some 



I then took all the text and the made them lowercase to help make analyzing them a bit more manageable.
I removed excess numbers, punctuation, and stop words (which are words that are common in the English language such as "the" and "so"). From there, I identified "stems" of the remaining words. This stemming process is used in text analysis so that words such as "decorated" and "decorations" are identified as the same word, since they both would be used in a similar manner to describe the decor of the coffeehouse.

From there, I found stem words with at least 10000 occurrences throughout the dataset. This 1000 in itself is arbitrary but since there are >7000 reviews, I believe that if words are in 1/7 of total reviews (including double counts), it should be considered in our model. 


One interesting idea that came up as an active user on Yelp was that there might be certain indicators from a restaurant or reviewer that might be a key factor of that particular rating. For example, maybe more excited reviewers and their reviews would overall be uplifing/positive, thus their reviews have more exclamation points. Critical reviews might be characterized by long rambling rants that point out all the flaws of one's experiences. Perhaps a more average or neutral review consistently talks about the quality of service. Thinking about what characterizes a 1 through 5 star review, I decided to look into text analysis and use a random forest model to parse out what are the most important identifiers that dictate review ratings.






Here are those key stem words:




With these words in mind, the appearance of them in a review was indicated with a 1 and will subsequently be used in the model as a predictor variable. 

### Methodology

A logistic regression was used 

A random forest was used instead of a logistic or a mulitnomial logistic/ordinal model because it is great for accuracy in classification, there are many predictor variables, and the key question I wanted to answer was: What are the most important elements when it comes to Yelp reviews.

49 predictors were used, which included the key stem words (excluded some common words from the top terms list), exclamation and question marks, and the length of the review.





```{r}

```

### RESULTS





```{r, include=FALSE}
data$anyword <- rowSums(data[, 9:54])

data %>%
  group_by(rating.level) %>%
  summarise(n = n(),
            avg.length = mean(length),
            any = mean(anyword)
            ) 

```


```{r, include=FALSE}
data.negative <- data %>%
  mutate(rating.level = case_when(rating.level == "Negative" ~ 1,
                             TRUE ~ 0)) %>%
  select(-c(coffee_shop_name, full_review_text, star_rating, rating, anyword))

data.neutral <- data %>%
  mutate(rating.level = case_when(rating.level == "Neutral" ~ 1,
                             TRUE ~ 0)) %>%
  select(-c(coffee_shop_name, full_review_text, star_rating, rating, anyword))

data.positive <- data %>%
  mutate(rating.level = case_when(rating.level == "Positive" ~ 1,
                             TRUE ~ 0)) %>%
  select(-c(coffee_shop_name, full_review_text, star_rating, rating, anyword))
```


```{r, echo=FALSE, warning=FALSE}
model.negative <- glm(rating.level ~ ., data = data.negative, family = binomial)
tidy.negative <- tidy(model.negative, exponentiate = TRUE)
model.neutral <- glm(rating.level ~ ., data = data.neutral, family = binomial)
tidy.neutral <- tidy(model.neutral, exponentiate = TRUE)
model.positive <- glm(rating.level ~ ., data = data.positive, family = binomial)
tidy.positive <- tidy(model.positive, exponentiate = TRUE)

rbind(tidy.negative, tidy.neutral, tidy.positive) %>%
  group_by(term) %>%
  dplyr::select(-statistic) %>% 
  filter(p.value < 0.05)  %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = ifelse(p.value < 0.001, "<0.001", sprintf("%0.3f", p.value))) %>%
  select(term, estimate, std.error, p.value) %>%
  kable(format = "latex", booktabs = T, longtable = T,
      col.names = c("Term", "Estimate", "Standard Error",
                      "P-Value"),
      digits = 3, centering = FALSE,
      align = "lrrr") %>%
  row_spec(0, bold = TRUE) %>%
  pack_rows("Negative Model", 1, 26, bold = T) %>%
  pack_rows("Neutral Model", 27, 48, bold = T) %>%
  pack_rows("Positive Model", 49, 72, bold = T) %>%
  kable_styling(latex_options = c("repeat_header"))

```


```{r,echo=FALSE, include=FALSE, warning=FALSE}
data.multi <- data %>%
  select(-c(coffee_shop_name, full_review_text, star_rating, rating, anyword))
model.multi <- multinom(rating.level ~ .,  data = data.multi)


tidy(model.multi, conf.int = TRUE, conf.level = 0.95) %>%
  dplyr::select(-statistic) %>%
  filter(p.value < 0.05)  %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = ifelse(p.value < 0.001, "<0.001", sprintf("%0.3f", p.value))) %>%
  kable(format = "latex", booktabs = T, linesep = "", longtable = T, 
        digits = 3) %>%
  kable_styling(latex_options = c("repeat_header"))
```


```{r}
data %>%
  group_by(rating.level) %>%
  summarise(n = n(),
            love = sum(love)
            ) 
```


### DISCUSSION

To understand how these identified important terms are associated with ratings, a partial dependence plot was used. 
*Generally, if a plot is positive, as the word appears in the review, it is associated with lower ratings. The opposite is true that if the plot appears negative, its presence in reviews is associated with higher ratings.

Here I will discuss more of why I believe certain words appear more promiently in certain types of reviews.

```{r}
data$rating <- as.numeric(data$rating)
ggplot(data, aes(x = rating)) + 
  geom_histogram() + 
  labs(title = 'Distribution of Ratings',
         x = 'Star-Rating',
         y = 'Count') 
```



I think to improve the model, I would want to think about "red/green flag words". The words that I chose in my analysis were the most common words because I wanted to see generally how certain wordings in peoples' reviews might be associated with the rating (for example, 5 star reviews will have more exclamation points and occurance of the word "love"). But there might be some words that weren't so common that might've uniquely been great proxies for ratings, especially at the extreme ends of the ratings system. For example, the word "horrible" is probably not used that many times, but when it is, it appears exclusively with 1 star ratings. 

Also not entirely sure if random trees was the most solid way to go. I wanted to do something a bit more advanced than logistic regression or multinomial so this was me being a bit brave and also naive at wanting to take this approach. 

```{r, echo=FALSE}
kable(sort(top_terms), col.names = "Term", caption = "Terms with over 1000 instances in reviews")
```


