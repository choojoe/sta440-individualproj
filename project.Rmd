---
title: "Individual Project: Analyzing Yelp Reviews"
output: pdf_document
---

There is plenty of work for me to complete with this individual project but I greatly appreciate any feedback on my work thus far!


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
library("dplyr")
library("stringr")
library("anytime")
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
library("randomForest")
library("randomForestExplainer")
library("caret")
library("knitr")
```

```{r load data, include=FALSE}
raw <- read.csv("raw_yelp_review_data.csv")
```

```{r mutate, include=FALSE}
raw <- raw %>%
  mutate(rating = as.factor(substr(raw$star_rating, 1, 2)),
         rating.level = as.factor(case_when(as.numeric(rating) == 5 ~ "Positive",
                                  as.numeric(rating) == 4 ~ "Neutral",
                                  as.numeric(rating) <= 3 ~ "Bad")),
         length = nchar(as.character(raw$full_review_text)),
         num.exclamations = str_count(raw$full_review_text, "!"),
         num.questions = str_count(raw$full_review_text, "\\?")
         )
data <- raw
```

# INTRO 

Yelp is a website where users can submit reviews of businesses. Reviews can help in a variety of ways: it can inform other people of the quality of the experience at said business, it can be a diary for the reviewer, and it can help local businesses receive valuable feedback. The reviews are from a 1-5 star scale system.

One of the things that I find interesting is the idea that there might be certain indicators from a restaurant or reviewer that might be a factor of that particular rating. For example, maybe more excited reviewers and their reviews would overall be uplifing/positive, thus their reviews have more exclamation points. Critical reviews might be characterized by long rambling rants that point out all the flaws of one's experiences. Perhaps a more average or neutral review consistently talks about the quality of service. Thinking about what characterizes a 1 through 5 star review, I decided to look into text analysis and use a random forest model to parse out what are the most important identifiers that dictate review ratings.


## DATA 

Data comes from kaggle: https://www.kaggle.com/sripaadsrinivasan/yelp-coffee-reviews and is comprised of 7616 coffee shop reviews in the Austin area. 
One of the dataset that comes within the kaggle is a ratings and sentiments csv; however, decoding each sentiment and what it meant with regards to the original review was too limiting. Therefore I did my own text analysis.

Firstly, I took the original length, the number of exclamations, and the number of question marks and saved their results. 
I then took all the text and the made them lowercase to help make analyzing them a bit more manageable.
I removed excess numbers, punctuation, and stop words (which are words that are common in the English language such as "the" and "so"). From there, I identified "stems" of the remaining words. This stemming process is used in text analysis so that words such as "decorated" and "decorations" are identified as the same word, since they both would be used in a similar manner to describe the decor of the coffeehouse.

From there, I found stem words with at least 10000 occurrences throughout the dataset. This 1000 in itself is arbitrary but since there are >7000 reviews, I believe that if words are in 1/7 of total reviews (including double counts), it should be considered in our model. 

Here are those key stem words:

```{r text, include=FALSE}
data$full_review_text <- as.character(data$full_review_text)
text <- data$full_review_text
text <- tolower(text)
text <- removeNumbers(text)
text <- removePunctuation(text)
text <- removeWords(text, stopwords("english"))
text <- stripWhitespace(text)
text <- stemDocument(text)
data$full_review_text <- text

corpus <- Corpus(VectorSource(data$full_review_text)) # turn into corpus

tdm <- TermDocumentMatrix(corpus) # create tdm from the corpus

top_terms <- findFreqTerms(tdm,1000)

# sort(top_terms)

data <- data %>%
  mutate(always = case_when(grepl("alway", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         austin = case_when(grepl("austin", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         back = case_when(grepl("back", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         barista = case_when(grepl("barista", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         checkin = case_when(grepl("checkin", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         coffee = case_when(grepl("coff", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         come = case_when(grepl("come", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         day = case_when(grepl("day", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         definite = case_when(grepl("definit", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         drink = case_when(grepl("drink", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         flavor = case_when(grepl("flavor", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         food = case_when(grepl("food", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         friend = case_when(grepl("friend", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         get = case_when(grepl("get", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         good = case_when(grepl("good", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         got = case_when(grepl("got", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         great = case_when(grepl("great", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         ice = case_when(grepl("ice", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         latte = case_when(grepl("latt", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         like = case_when(grepl("like", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         little = case_when(grepl("littl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         look = case_when(grepl("look", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         lot = case_when(grepl("lot", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         love = case_when(grepl("love", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         nice = case_when(grepl("nice", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         order = case_when(grepl("order", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         park = case_when(grepl("park", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         people = case_when(grepl("peopl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         place = case_when(grepl("place", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         pretty = case_when(grepl("pretti", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         really = case_when(grepl("realli", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         seat = case_when(grepl("seat", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         service = case_when(grepl("servic", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         shop = case_when(grepl("shop", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         spot = case_when(grepl("spot", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         staff = case_when(grepl("staff", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         sweet = case_when(grepl("sweet", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         table = case_when(grepl("tabl", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         taste = case_when(grepl("tast", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         tea = case_when(grepl("tea", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         time = case_when(grepl("time", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         try = case_when(grepl("tri", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         want = case_when(grepl("want", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         well = case_when(grepl("well", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         will = case_when(grepl("will", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0),
         work = case_when(grepl("work", full_review_text, fixed=TRUE) ~ 1,
                             TRUE ~ 0)
  )
```

```{r, echo=FALSE}
kable(sort(top_terms), col.names = "Term", caption = "Terms with over 1000 instances in reviews")
```

With these words in mind, the appearance of them in a review was indicated with a 1 and will subsequently be used in the model as a predictor variable. 

### METHODOLOGY

A random forest model was used.

A random forest was used instead of a logistic or a mulitnomial logistic/ordinal model because it is great for accuracy in classification, there are many predictor variables, and the key question I wanted to answer was: What are the most important elements when it comes to Yelp reviews.

49 predictors were used, which included the key stem words (excluded some common words from the top terms list), exclamation and question marks, and the length of the review.





```{r}
require(caTools)
set.seed(440)
data.model <- subset(data, select = -c(coffee_shop_name, full_review_text, star_rating, rating.level))

sample = sample.split(data.model$rating, SplitRatio = .75)
train = subset(data.model, sample == TRUE)
test  = subset(data.model, sample == FALSE)
dim(train)
dim(test)

rf <- randomForest(rating ~ ., train) 
print(rf)



```

### RESULTS



To get a semblance of how well our model fits, I made a training vs test set that performed decently well (about 57% on the test set).

The 20 most important variables were:
"length"
"number of exclamations"
"place"            
"coffee"           
"great"           
"good"            
"checkin"         
"try"             
"num.questions"    
"get"             
"friend"           
"like"             
"shop"             
"ice"              
"love"            
"drink"            
"austin"           
"really"           
"day"             
"food" 



```{r}
p1 <- predict(rf, train)
confusionMatrix(p1, train$rating)
plot(rf)

p2 <- predict(rf, test)
confusionMatrix(p2, test$rating)
```




```{r}
plot(rf)

hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")
varImpPlot(rf,
           sort = T,
           n.var = 20,
           main = "Top 20 - Variable Importance")
importance(rf)


```
```{r}
imp <- varImp(rf)
impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
impvar <- impvar[1:10]


for (i in seq_along(impvar)) {
    partialPlot(rf, train, impvar[i], xlab=impvar[i],
                main=paste("Partial Dependence on", impvar[i]))
}


```


```{r}
data %>%
  group_by(rating) %>%
  summarise(n = n(),
            avg.length = mean(length),
            excl = mean(num.exclamations),
            place = mean(place),
            great = mean(great),
            coffee = mean(coffee),
            quest = mean(num.questions),
            try = mean(try),
            checkin = mean(checkin),
            friend = mean(friend),
            get = mean(get)
            ) 

```


### DISCUSSION

To understand how these identified important terms are associated with ratings, a partial dependence plot was used. 
*Generally, if a plot is positive, as the word appears in the review, it is associated with lower ratings. The opposite is true that if the plot appears negative, its presence in reviews is associated with higher ratings.

Here I will discuss more of why I believe certain words appear more promiently in certain types of reviews.





I think to improve the model, I would want to think about "red/green flag words". The words that I chose in my analysis were the most common words because I wanted to see generally how certain wordings in peoples' reviews might be associated with the rating (for example, 5 star reviews will have more exclamation points and occurance of the word "love"). But there might be some words that weren't so common that might've uniquely been great proxies for ratings, especially at the extreme ends of the ratings system. For example, the word "horrible" is probably not used that many times, but when it is, it appears exclusively with 1 star ratings. 

Also not entirely sure if random trees was the most solid way to go. I wanted to do something a bit more advanced than logistic regression or multinomial so this was me being a bit brave and also naive at wanting to take this approach. 




